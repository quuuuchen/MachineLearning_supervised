{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Regression\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab you will apply regression to some realistic data. In this lab you will work with the automotive price dataset. Your goal is to construct a linear regression model to predict the price of automobiles from their characteristics. \n",
    "\n",
    "In this lab will learn to:\n",
    "\n",
    "1. Use categorical data with scikit-learn. \n",
    "2. Apply transformations to features and labels to improve model performance. \n",
    "3. Compare regression models to improve model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "As a first, step you will load the dataset into the notebook environment. \n",
    "\n",
    "First, execute the code in the cell below to load  the packages you will need to run the rest of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below loads the dataset which was prepared using steps from the Data Preparation lab.Execute this code and ensure that the expected columns are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['CustomerID', 'AveMonthSpend', 'Title', 'FirstName', 'MiddleName',\n",
       "       'LastName', 'Suffix', 'AddressLine1', 'AddressLine2', 'City',\n",
       "       'StateProvinceName', 'CountryRegionName', 'PostalCode', 'PhoneNumber',\n",
       "       'BirthDate', 'Education', 'Occupation', 'Gender', 'MaritalStatus',\n",
       "       'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome',\n",
       "       'TotalChildren', 'YearlyIncome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('AW_AveMonthSpend.csv')\n",
    "ds2 = pd.read_csv('AdvWorksCusts.csv')\n",
    "total=pd.merge(ds,ds2)\n",
    "print(total.shape)\n",
    "total.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>AveMonthSpend</th>\n",
       "      <th>Title</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Suffix</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>AddressLine2</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HomeOwnerFlag</th>\n",
       "      <th>NumberCarsOwned</th>\n",
       "      <th>NumberChildrenAtHome</th>\n",
       "      <th>TotalChildren</th>\n",
       "      <th>YearlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11000</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>V</td>\n",
       "      <td>Yang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3761 N. 14th St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rockhampton</td>\n",
       "      <td>...</td>\n",
       "      <td>1966-04-08</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>137947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11001</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>L</td>\n",
       "      <td>Huang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2243 W St.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seaford</td>\n",
       "      <td>...</td>\n",
       "      <td>1965-05-14</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>101141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11002</td>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruben</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Torres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5844 Linden Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>...</td>\n",
       "      <td>1965-08-12</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>91945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11003</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1825 Village Pl.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Ryde</td>\n",
       "      <td>...</td>\n",
       "      <td>1968-02-15</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11004</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7553 Harness Circle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wollongong</td>\n",
       "      <td>...</td>\n",
       "      <td>1968-08-08</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  AveMonthSpend Title  FirstName MiddleName LastName Suffix  \\\n",
       "0       11000             89   NaN        Jon          V     Yang    NaN   \n",
       "1       11001            117   NaN     Eugene          L    Huang    NaN   \n",
       "2       11002            123   NaN      Ruben        NaN   Torres    NaN   \n",
       "3       11003             50   NaN    Christy        NaN      Zhu    NaN   \n",
       "4       11004             95   NaN  Elizabeth        NaN  Johnson    NaN   \n",
       "\n",
       "          AddressLine1 AddressLine2         City      ...        BirthDate  \\\n",
       "0      3761 N. 14th St          NaN  Rockhampton      ...       1966-04-08   \n",
       "1           2243 W St.          NaN      Seaford      ...       1965-05-14   \n",
       "2     5844 Linden Land          NaN       Hobart      ...       1965-08-12   \n",
       "3     1825 Village Pl.          NaN   North Ryde      ...       1968-02-15   \n",
       "4  7553 Harness Circle          NaN   Wollongong      ...       1968-08-08   \n",
       "\n",
       "    Education    Occupation Gender MaritalStatus HomeOwnerFlag  \\\n",
       "0  Bachelors   Professional      M             M             1   \n",
       "1  Bachelors   Professional      M             S             0   \n",
       "2  Bachelors   Professional      M             M             1   \n",
       "3  Bachelors   Professional      F             S             0   \n",
       "4  Bachelors   Professional      F             S             1   \n",
       "\n",
       "  NumberCarsOwned NumberChildrenAtHome TotalChildren  YearlyIncome  \n",
       "0               0                    0             2        137947  \n",
       "1               1                    3             3        101141  \n",
       "2               1                    3             3         91945  \n",
       "3               1                    0             0         86688  \n",
       "4               4                    5             5         92771  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are both numeric and categorical features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model matrix.\n",
    "\n",
    "All scikit-learn models require a numpy array of numeric only values for the features. The resulting array is often referred to as the **model matrix**. \n",
    "\n",
    "To create a model matrix from cases with both numeric and categorical variables requires two steps. First, the numeric features must be rescaled. Second, the categorical variables must be converted to a set of **dummy variables** to encode the presence or not of each category.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables from categorical features\n",
    "\n",
    "Now, you must create dummy variables for the categorical features. Dummy variables encode categorical features as a set of binary variables. There is one dummy variable for each possible category. For each case all of the values in the dummy variables are set to zero, except the one corresponding to the category value, which is set to one. In this way, a categorical variable with any number of categories can be encoded as series of numeric features which scikit-learn can operate on. This process is referred to as **one hot encoding** since only one dummy variable is coded as 1 (hot) per case. \n",
    "\n",
    "The `sklearn.preprocessing` package contains functions to encode categorical features as dummy variables in two steps;\n",
    "1. The categories are  encoded as numbers starting with 0. For example, if there are 5 categories, they are encoded as the set $\\{ 0,1,2,3,4 \\}$.\n",
    "2. The numeric categories are then encoded as dummy variables. \n",
    "\n",
    "The following example will give you a feel for how this process works. The code in the cell below computes the numeric representation of the categories for the `body_style` feature by the following steps:\n",
    "\n",
    "1. An encoder object is created using the `LabelEncoder` method.\n",
    "2. The encoder is `fit` to the unique string values of the feature. \n",
    "3. The `transformation` method then applies the numeric encoding to the original feature. \n",
    "\n",
    "Execute the code in the cell below and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Professional' 'Management' 'Skilled Manual' 'Clerical' 'Manual']\n",
      "[3 3 3 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(total['Occupation'].unique())\n",
    "Features = total['Occupation']\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(Features)\n",
    "Features = enc.transform(Features)\n",
    "print(Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this five original body style categories of this feature is now coded as integers in the set $\\{ 0,1,2,3,4 \\}$.\n",
    "\n",
    "For the next step in the process, the numerically coded categorical variable is converted to a set of dummy variables following these steps:\n",
    "1. A one hot encoder object is created using the `OneHotEncoder` method from the `sklearn.preprocessing` module.\n",
    "2. The numerically coded categorical feature is fit with the one hot encoder. \n",
    "3. The dummy variables are encoded using the `transform` method on the encodings.\n",
    "\n",
    "Execute the code in the cell below and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = preprocessing.OneHotEncoder()\n",
    "encoded = ohe.fit(Features.reshape(-1,1))\n",
    "Features = encoded.transform(Features.reshape(-1,1)).toarray()\n",
    "Features[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `body_style` feature has been encoded as five columns. Each of these columns is a dummy variable representing one category. Each row has one and only one dummy variable with a 1, and the rest 0s. This is the one hot encoding. \n",
    "\n",
    "Now, you need to one hot encode all five categorical variables and append them as columns to the model matrix with the scaled numeric variables. The code in the cell below executes a `for` loop that calls the `encode_string` function and uses the numpy `concatenate` function to add the dummy variables to the model matrix. The `encode_string` function uses the same process discussed above. \n",
    "\n",
    "Execute this code, verify the result, and answer **Question 1** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 20)\n",
      "[[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def encode_string(cat_feature):\n",
    "    ## First encode the strings to numeric categories\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(cat_feature)\n",
    "    enc_cat_feature = enc.transform(cat_feature)\n",
    "    ## Now, apply one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_cat_feature.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_feature.reshape(-1,1)).toarray()\n",
    "    \n",
    "\n",
    "categorical_columns = ['CountryRegionName',  'Gender', \n",
    "                       'MaritalStatus', 'Education']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(total[col])\n",
    "    Features = np.concatenate([Features, temp], axis = 1)\n",
    "\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model matrix now has 14 features which encode the five origianalcategorical features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the numeric features\n",
    "\n",
    "To complete the model matrix, execute the code in the cell below to concatenate the three numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 23)\n",
      "[[0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.37947e+05]\n",
      " [0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 3.00000e+00 1.01141e+05]]\n"
     ]
    }
   ],
   "source": [
    "Features = np.concatenate([Features, np.array(total[['NumberCarsOwned', \n",
    "                            'NumberChildrenAtHome', 'YearlyIncome']])], axis = 1)\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 17 features, 14 dummy variables and 3 numeric features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset\n",
    "\n",
    "With the model matrix constructed, you must now create randomly sampled training and test data sets. The code in the cell below uses the `train_test_split` function from the `sklearn.model_selection` module to Bernoulli sample the cases in the original dataset into the two subsets. Since this data set is small only 40 cases will be included in the test dataset. Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Management' 'Skilled Manual' 'Manual' 'Clerical' 'Professional']\n",
      "[1 4 1 4 2 0 4 3 2 4 3 3 4 3 4 3 4 4 1 0 2 4 3 4 3 1 4 3 3 1 4 1 1 1 3 0 1\n",
      " 4 3 4 3 2 4 0 4 4 2 4 1 0 1 3 1 2 3 4 3 4 4 0 0 0 3 3 2 4 3 1 0 3 3 1 3 0\n",
      " 0 3 0 4 3 3 4 4 0 1 0 0 3 1 2 1 1 4 1 4 2 3 2 4 4 3 1 1 4 1 3 3 2 1 3 1 3\n",
      " 4 3 0 4 3 0 4 4 3 4 3 3 0 4 3 0 4 2 1 4 2 4 3 3 1 3 4 3 3 3 4 1 4 3 3 4 2\n",
      " 2 4 4 0 0 4 1 0 3 0 3 3 4 4 4 4 3 1 1 3 3 0 0 3 4 1 0 0 1 4 2 3 2 4 3 1 2\n",
      " 3 4 2 4 0 4 1 3 1 1 4 3 3 1 1 3 4 2 4 3 3 1 3 1 0 4 2 4 4 4 3 4 3 4 0 4 4\n",
      " 1 4 2 3 3 3 2 4 0 1 4 2 3 2 2 4 3 0 3 3 0 2 3 0 0 0 1 3 3 4 2 1 1 3 4 4 1\n",
      " 4 0 4 1 4 0 3 4 3 1 3 3 0 1 0 3 0 3 3 2 4 3 3 4 2 2 2 4 0 1 2 0 3 4 3 0 1\n",
      " 3 2 0 2 3 4 1 4 1 0 3 1 3 1 0 3 3 3 4 4 4 3 3 3 0 2 4 3 1 2 4 3 4 3 1 4 0\n",
      " 4 3 1 3 4 3 4 3 4 4 3 0 2 3 2 3 1 1 0 1 4 1 1 4 3 2 3 1 3 4 3 0 2 0 3 0 4\n",
      " 3 0 4 2 3 3 4 0 0 1 4 3 2 1 3 3 1 2 4 4 4 1 0 4 4 4 3 2 2 4 1 3 1 3 4 3 4\n",
      " 4 4 0 3 0 1 4 0 4 3 1 1 4 1 0 3 2 1 4 0 2 2 2 0 3 3 3 0 0 3 1 4 1 4 1 3 1\n",
      " 2 3 4 2 0 4 2 4 3 4 1 4 3 4 4 3 1 0 3 2 3 3 4 3 4 3 3 3 3 0 2 4 0 1 1 4 1\n",
      " 4 1 0 0 2 1 3 1 1 0 3 1 3 3 4 1 1 3 4]\n",
      "(500, 20)\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]]\n",
      "(500, 23)\n",
      "[[0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 2.00000e+00 0.00000e+00 8.69310e+04]\n",
      " [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 2.00000e+00 2.00000e+00 1.00125e+05]]\n",
      "(500, 19)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('AW_test.csv')\n",
    "\n",
    "print(test['Occupation'].unique())\n",
    "Features1 = test['Occupation']\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(Features1)\n",
    "Features1 = enc.transform(Features1)\n",
    "print(Features1)\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "encoded = ohe.fit(Features1.reshape(-1,1))\n",
    "Features1 = encoded.transform(Features1.reshape(-1,1)).toarray()\n",
    "Features1[:10,:]\n",
    "\n",
    "def encode_string(cat_features):\n",
    "    ## First encode the strings to numeric categories\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    ## Now, apply one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()\n",
    "\n",
    "categorical_columns = ['CountryRegionName',  'Gender', \n",
    "                       'MaritalStatus', 'Education']\n",
    "\n",
    "Features1 = encode_string(test['Occupation'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(test[col])\n",
    "    Features1 = np.concatenate([Features1, temp], axis = 1)\n",
    "\n",
    "print(Features1.shape)\n",
    "print(Features1[:2, :]) \n",
    "\n",
    "Features1 = np.concatenate([Features1, np.array(test[['NumberCarsOwned', \n",
    "                            'NumberChildrenAtHome', 'YearlyIncome']])], axis = 1)\n",
    "print(Features1.shape)\n",
    "print(Features1[:2, :])\n",
    "\n",
    "test=test.drop(columns=['AddressLine2','Title','MiddleName','Suffix'])\n",
    "test.head()\n",
    "\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total.head()\n",
    "print(total.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 23)\n"
     ]
    }
   ],
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(9988)\n",
    "labels = np.array(total['AveMonthSpend'])\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 40)\n",
    "print(Features.shape)\n",
    "x_train = Features\n",
    "y_train = np.ravel(labels)\n",
    "x_test = Features1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale numeric features\n",
    "\n",
    "Numeric features must be rescaled so they have a similar range of values. Rescaling prevents features from having an undue influence on model training simply because then have a larger range of numeric variables. \n",
    "\n",
    "The code in the cell below uses the `StandardScaler` function from the Scikit Learn preprocessing package to Zscore scale the numeric features. Notice that the scaler is fit only on the training data. The trained scaler is these applied to the test data. Test data should always be scaled using the parameters from the training data. \n",
    "\n",
    "Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.50809351],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 3.        , 0.58046477],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 3.        , 0.34869621],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.21620302],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        4.        , 5.        , 0.36951404]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x_train[:,22:])\n",
    "x_train[:,22:] = scaler.transform(x_train[:,22:])\n",
    "x_test[:,22:] = scaler.transform(x_test[:,22:])\n",
    "print(x_train.shape)\n",
    "x_train[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the numeric features have been rescaled are required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the linear regression model\n",
    "\n",
    "With data prepared and split into training and test subsets, you will now compute the linear regression model. With the dummy variables created there are 17 features, so the model will require 17 coefficients. There is no intercept specified since we are working with dummy variables. The equation for such a **multiple regression** problem can be written as:\n",
    "\n",
    "$$\\hat{y} = f(\\vec{x}) = \\vec{\\beta} \\cdot \\vec{x} + b\\\\ = \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n + b$$  \n",
    "where; \n",
    "$\\hat{y}$ are the predicted values or scores,   \n",
    "$\\vec{x}$ is the vector of feature values with components $\\{ x_1, x_2, \\cdots, x_n$,  \n",
    "$\\vec{\\beta}$ is vector of model coefficients with components $\\{ \\beta_1, \\beta_2, \\cdots, \\beta_n$,  \n",
    "$b$ is the intercept term, if there is one.\n",
    "\n",
    "You can think of the linear regression function $f(\\vec{x})$ as the dot product between the beta vector $\\vec{\\beta}$ and the feature vector $\\vec{x}$, plus the intercept term $b$.\n",
    "\n",
    "The code in the cell below uses the `sklearn import linear_model` to compute a least squares linear model as follows:\n",
    "1. A linear regression model object is created with the `LinearRegression` method. Notice, that in this case, no intercept will be fit. The intercept value or **bias** will be accommodated in the coefficients of the dummy variables for the categorical features. \n",
    "2. The model is fit using the `fit` method with the numpy array of features and the label. \n",
    "\n",
    "Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define and fit the linear regression model\n",
    "lin_mod = linear_model.LinearRegression(fit_intercept = False)\n",
    "lin_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been fit to the training data. Execute the code in the cell below to examine the value of the intercept term and coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[ 9.75261282e+11  9.75261282e+11  9.75261282e+11  9.75261282e+11\n",
      "  9.75261282e+11 -1.11237141e+13 -1.11237141e+13 -1.11237141e+13\n",
      " -1.11237141e+13 -1.11237141e+13 -1.11237141e+13  4.09489242e+12\n",
      "  4.09489242e+12  3.77832380e+12  3.77832380e+12  2.27523662e+12\n",
      "  2.27523662e+12  2.27523662e+12  2.27523662e+12  2.27523662e+12\n",
      " -4.62830713e-01  1.11315723e+01  8.90485020e+00]\n",
      "[ 42.71765137 107.0234375   50.28613281  89.08398438  60.95898438\n",
      "  43.58789062  96.15527344 127.59667969 103.29199219  55.40527344\n",
      "  60.49951172  50.41162109  73.07617188  46.79492188  36.20617676\n",
      "  51.10253906  86.0546875   74.07226562 110.38671875  59.29187012\n",
      "  67.79296875  76.07373047 148.68164062  85.73828125  52.84667969\n",
      "  76.60546875  86.48632812 117.24609375  78.58789062  60.20214844\n",
      "  69.89221191  79.77734375  40.76757812  71.80273438 106.56884766\n",
      " 103.57519531 147.37402344  92.359375    58.31445312  87.00195312\n",
      "  46.8076771   80.81542969  81.21875     48.32470703  57.35449219\n",
      "  76.0390625   61.95117188  88.69091797 115.84570312  79.66765744\n",
      "  82.9375      95.85546875  79.82519531  66.3046875   46.89648438\n",
      "  76.29492188  58.8828125   74.89550781  65.68574187  68.38867188\n",
      "  45.4921875   65.49023438  92.45703125  83.31768836  44.31424943\n",
      "  82.16259766  82.20019531 132.07279211  64.68164062 107.51953125\n",
      "  86.33251953  69.88867188  94.53125     44.57226562  68.41601562\n",
      "  82.69433594 113.83886719  69.50537109  61.62402344  45.59912109\n",
      "  88.33105469  74.29980469  47.30175781  89.51171875  85.84033203\n",
      "  48.68847656  84.65429688 120.71484375  98.30664062  53.54492188\n",
      "  54.47851562  95.94335938  37.45019531  49.86376953  37.42675781\n",
      " 140.24804688  58.99023438  49.12597656  46.625       53.84667969\n",
      " 104.44970703  75.69140625  49.84765625 119.6953125   85.24609375\n",
      " 105.07519531  32.24609375  47.23718262  46.16711201  60.09814453\n",
      "  96.01806641  48.19580078  85.56884766  64.45019531  75.46289062\n",
      "  86.77246094  37.66540527  39.45239258  47.81738281  88.73876953\n",
      " 125.19873047  87.91015625  83.09179688  40.09863281  78.21484375\n",
      "  57.45996094  66.18457031  92.0390625   87.36621094 126.91210938\n",
      "  36.77734375  88.19799805 120.4453125   42.60949482  48.91748047\n",
      " 113.63232422 153.03515625  85.2578125   85.57666016  83.02148438\n",
      "  90.87255859  42.68359375 118.03125     34.19750977  79.54785156\n",
      "  62.26074219  51.60449219  37.7890625   63.8828125   64.29394531\n",
      "  99.57519531  69.66601562  68.39160156  78.71484375 106.93066406\n",
      "  36.41345215  75.63867188  71.71191406  80.31933594  96.65185547\n",
      "  39.56542969  71.17675781  60.79748535  96.76171875 107.25\n",
      "  59.05371094  97.3359375  104.8515625   92.26171875  36.3470459\n",
      "  79.26953125  79.10766751  80.27575475  79.49804688  40.24511719\n",
      "  32.72302246 107.8046875   72.90820312  50.33105469 136.13720703\n",
      "  39.12402344  40.16821289 106.46484375  75.88134766  31.21008076\n",
      "  41.07177734  61.91271973  65.9140625   50.80273438  57.9453125\n",
      "  81.921875    80.7734375   75.63232422  81.72460938  92.71875\n",
      "  71.21191406  46.82763672  74.984375    51.42480469  93.89221191\n",
      "  59.66015625  80.49188148  32.40625     80.39648438 131.28710938\n",
      "  82.81445312 113.68359375  98.13134766  67.24316406  70.69726562\n",
      "  77.31835938  69.8359375  122.66113281  43.03515625  45.44152832\n",
      "  78.90917969  45.65332031  59.40429688  80.9609375   80.49609375\n",
      "  39.74804688  76.22070312 103.98144531  68.53088379  60.4375\n",
      "  47.30859375  60.4140625  102.734375    83.09472656  88.09765625\n",
      "  89.60839844  52.11035156  72.484375    68.41455078 107.15136719\n",
      "  68.12109375  93.01464844  96.04492188  41.52740366  74.51953125\n",
      "  88.52685547  64.95117188  38.1875      59.30664062  69.29003906\n",
      "  46.75        77.65234375  69.71289062  81.76464844  87.56884766\n",
      " 106.82421875  56.36816406  52.8203125   39.83105469 130.22070312\n",
      "  94.80029297  52.05908203  81.01953125 123.59472656  80.72460938\n",
      "  43.86425781  68.39257812  87.40625     66.3203125   80.73046875\n",
      "  69.65820312  44.03735352  78.25878906 110.22167969  60.30078125\n",
      " 110.4375      41.03857422  84.19140625  66.09863281 105.55566406\n",
      "  41.16308594 139.52392578  50.87603647 117.05371094  74.73828125\n",
      "  91.74023438  61.34863281  71.84179688  57.89550781  53.22607422\n",
      "  30.453125    74.81933594  44.18457031  44.14648438  70.4375\n",
      "  78.20703125  49.37402344  86.15820312 141.37890625  75.51171875\n",
      " 110.72558594 139.76416016  39.25390625  65.72070312  37.52392578\n",
      "  46.93359375  56.31152344 120.8046875  102.82226562  77.19921875\n",
      "  35.53320312 101.36045341 143.75549072 124.14648438  76.77478027\n",
      "  40.68383789 106.97070312 152.23632812  53.08691406  80.515625\n",
      "  42.4765625   35.8359375   65.97753906 143.62207031  72.67773438\n",
      "  72.63671875  67.04101562  53.91357422  34.75       139.54345703\n",
      "  61.05859375  43.28320312  82.75292969  57.26660156  46.66796875\n",
      "  89.83203125  83.08984375 113.75488281  55.79394531  71.01717073\n",
      " 114.57910156  79.13769531  37.28027344 116.48730469  49.77636719\n",
      "  92.58203125  74.93115234  74.58007812  78.11621094  74.73046875\n",
      "  63.63964844  79.12402344  57.48535156 112.03222656  82.32519531\n",
      "  72.81347656  78.40917969  44.70202637  58.9921875   50.17578125\n",
      "  89.62060547  84.94873047  55.57568359  60.40136719  53.62451172\n",
      " 109.3984375   69.01757812  75.97119141  77.20898438  69.55859375\n",
      "  60.50097656  43.32421875  51.02734375  44.51757812  64.47949219\n",
      " 136.52197266  43.69677734  91.640625    71.97460938  84.92431641\n",
      "  45.68365366  76.34277344  43.43164062  38.70629883 138.71044922\n",
      "  98.10449219  82.46606595  31.19054951  88.15234375  45.76367188\n",
      "  82.23632812 117.5703125   46.74393693  88.03564453  83.28857422\n",
      "  92.47070312  54.88085938 119.94335938  72.75390625  45.89453125\n",
      "  76.42675781  83.41894531  38.25390625  64.82421875  75.0023075\n",
      "  50.64941406 143.30517578 113.04882812  92.08935547  60.39416504\n",
      "  85.99804688 105.63867188  43.95507812  81.80273438  46.04833984\n",
      " 107.17480469  65.12304688  77.99609375  59.40332031  88.04492188\n",
      "  74.09960938  86.12255859 143.57863936  98.77539062  67.48242188\n",
      "  74.88623047  33.9173584   55.04785156  68.76757812  52.56054688\n",
      "  44.74023438  48.02246094  60.67285156  60.859375    63.32714844\n",
      "  37.78320312 101.09082031  93.14257812 117.06347656 111.64648438\n",
      "  79.95703125  69.57967073  73.36376953  75.13671875  93.77832031\n",
      "  52.24609375 108.55273438  91.16796875 117.73242188  38.84863281\n",
      "  77.29785156  45.39355469 109.35595703  63.9765625   45.47607422\n",
      "  59.83789062 118.58203125  84.71679688  52.12792969  76.07421875\n",
      "  53.99511719  81.28710938  69.86230469  49.13085938  94.50390625\n",
      "  86.22070312  36.13500977 103.23632812  38.07519531 104.234375\n",
      "  81.22265625  55.19042969  89.02197266  53.49658203  61.05859375\n",
      "  47.0546875   87.16796875  94.46289062  48.07617188  60.07519531\n",
      "  66.74121094  71.09179688 138.32639946 132.04394531 128.29736328\n",
      " 129.77734375  82.18554688 109.72998047  74.65478516  73.58203125\n",
      "  30.84869272 146.61669922  49.91699219  88.65234375  91.12011719\n",
      "  71.1373291  100.78125    139.98388672  78.08496094  56.25292969\n",
      "  48.33984375  90.86328125  86.67016602  55.63427734  32.28027344]\n"
     ]
    }
   ],
   "source": [
    "print(lin_mod.intercept_)\n",
    "print(lin_mod.coef_)\n",
    "y_score = lin_mod.predict(x_test)\n",
    "print(y_score)\n",
    "np.savetxt(\"AVS.csv\",y_score, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the intercept term is `0.0`. Roughly speaking, you can interpret the coefficients of the model as follows:  \n",
    "1. The price of autos increases with weight (first coefficient), horsepower (second coefficient) and weakly decreases with fuel efficiency (third coefficient). \n",
    "2. The coefficients for the dummy variables are in a similar range, indicating the bias or intercept has been incorporated in these. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "You will now use the test dataset to evaluate the performance of the regression model. As a first step, execute the code in the cell below to compute and display various performance metrics and examine the results. Then, answer **Question 2** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2d9965c833d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlin_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "def print_metrics(y_true, y_predicted, n_parameters):\n",
    "    ## First compute R^2 and the adjusted R^2\n",
    "    r2 = sklm.r2_score(y_true, y_predicted)\n",
    "    r2_adj = r2 - (n_parameters - 1)/(y_true.shape[0] - n_parameters) * (1 - r2)\n",
    "    \n",
    "    ## Print the usual metrics and the R^2 values\n",
    "    print('Mean Square Error      = ' + str(sklm.mean_squared_error(y_true, y_predicted)))\n",
    "    print('Root Mean Square Error = ' + str(math.sqrt(sklm.mean_squared_error(y_true, y_predicted))))\n",
    "    print('Mean Absolute Error    = ' + str(sklm.mean_absolute_error(y_true, y_predicted)))\n",
    "    print('Median Absolute Error  = ' + str(sklm.median_absolute_error(y_true, y_predicted)))\n",
    "    print('R^2                    = ' + str(r2))\n",
    "    print('Adjusted R^2           = ' + str(r2_adj))\n",
    "   \n",
    "y_score = lin_mod.predict(x_test) \n",
    "print_metrics(y_test, y_score, 28)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, these metrics look promising. The RMSE, MAE and median absolute error are all small and in a similar range. However, notice that the $R^2$ and $R^2_{adj}$ are rather different. This model has a large number of parameters compared to the number of cases available. This result indicates that the model may be overfit and might not generalize well. \n",
    "\n",
    "To continue the evaluation of the model performance, execute the code in the cell below to display a histogram of the residuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_resids(y_test, y_score):\n",
    "    ## first compute vector of residuals. \n",
    "    resids = np.subtract(y_test.reshape(-1,1), y_score.reshape(-1,1))\n",
    "    ## now make the residual plots\n",
    "    sns.distplot(resids)\n",
    "    plt.title('Histogram of residuals')\n",
    "    plt.xlabel('Residual value')\n",
    "    plt.ylabel('count')\n",
    "    \n",
    "hist_resids(y_test, y_score)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows that the residuals are in a small range. However, there is some noticeable skew in the distribution. \n",
    "\n",
    "Next, execute the code in the cell below to display the Q-Q Normal plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resid_qq(y_test, y_score):\n",
    "    ## first compute vector of residuals. \n",
    "    resids = np.subtract(y_test.reshape(-1,1), y_score.reshape(-1,1))\n",
    "    ## now make the residual plots\n",
    "    ss.probplot(resids.flatten(), plot = plt)\n",
    "    plt.title('Residuals vs. predicted values')\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('Residual')\n",
    "    \n",
    "resid_qq(y_test, y_score)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the histogram, the Q-Q Normal plot indicates the residuals are close to Normally distributed, show some skew (deviation from the straight line). This is particularly for large residuals. \n",
    "\n",
    "There is one more diagnostic plot. Execute the code in the cell below to display the plot of residuals vs. predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resid_plot(y_test, y_score):\n",
    "    ## first compute vector of residuals. \n",
    "    resids = np.subtract(y_test.reshape(-1,1), y_score.reshape(-1,1))\n",
    "    ## now make the residual plots\n",
    "    sns.regplot(y_score, resids, fit_reg=False)\n",
    "    plt.title('Residuals vs. predicted values')\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('Residual')\n",
    "\n",
    "resid_plot(y_test, y_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot looks reasonable. The residual values appear to have a fairly constant dispersion as the predicted value changes. A few large residuals are noticeable, particularly on the positive side.\n",
    "\n",
    "But, wait! This residual plot is for the log of the auto price. What does the plot look like when transformed to real prices? Execute the code in the cell below to find out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_untransform = np.exp(y_score)\n",
    "y_test_untransform = np.exp(y_test)\n",
    "resid_plot(y_test_untransform, y_score_untransform) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the untransformed residuals show a definite trend. The dispersion of the residuals has a cone-like pattern increasing to the right. The regression model seems to do a good job of predicting the price of low cost cars, but becomes progressively worse as the price of the car increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson you have done the following in the process of constructing and evaluating a multiple linear regression model:   \n",
    "1. Transformed the label value to make it more symmetric and closer to a Normal distribution.\n",
    "2. Aggregated categories of a categorical variable to improve the statistical representation. \n",
    "3. Scaled the numeric features. \n",
    "4. Recoded the categorical features as binary dummy variables. \n",
    "5. Fit the linear regression model using scikit-learn. \n",
    "6. Evaluated the performance of the model using both numeric and graphical methods. \n",
    "\n",
    "It is clear from the outcome of the performance evaluation that this model needs to be improved. As it is, the model shows poor generalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auto_prices['body_style'].unique())\n",
    "Features = auto_prices['body_style']\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(Features)\n",
    "Features = enc.transform(Features)\n",
    "print(Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
